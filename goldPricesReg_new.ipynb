{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    driver.get(\"https://finance.yahoo.com/quote/GC%3DF/history/\")\n",
    "    wait = WebDriverWait(driver, 10)    \n",
    "    \n",
    "    calendar_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//span[@class='label yf-1th5n0r']\")))\n",
    "    calendar_button.click()\n",
    "    time.sleep(1)\n",
    "    date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Max']\")))\n",
    "    date_input.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    rows = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//tbody//tr\")))\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        row_data = [cell.text for cell in cells]\n",
    "        data.append(row_data) \n",
    "        print(row_data)\n",
    "\n",
    "    columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    df.to_csv(\"gold_max.csv\", index=False)\n",
    "    print(\"Data saved to 'gold.csv'.\")\n",
    "    print(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, QuantileRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"gold_max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_integer(date_str):\n",
    "    try:\n",
    "        date_obj = datetime.strptime(date_str, \"%b %d, %Y\")\n",
    "        return int(date_obj.strftime(\"%d%m%Y\"))\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing date: {e}\")\n",
    "        return None\n",
    "\n",
    "df['Date'] = df['Date'].apply(date_to_integer)\n",
    "\n",
    "columns_to_convert = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "for column in columns_to_convert:\n",
    "    df[column] = df[column].astype(str)\n",
    "    df[column] = df[column].replace('-', np.nan)\n",
    "    df[column] = df[column].str.replace(',', '').astype(float)\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "df=df.dropna()\n",
    "print(df)\n",
    "\n",
    "X = df[['Date', 'Open','High','Low','Adj Close']]\n",
    "Y = df['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "linearReg=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=42)\n",
    "\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "lassoReg=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=42)\n",
    "\n",
    "model = Ridge(alpha=0.1)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "ridgeReg=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=42)\n",
    "\n",
    "model = QuantileRegressor(quantile=0.5,alpha=0.1)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_quantile = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred_quantile)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_quantile)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred_quantile)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "quantileReg=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBRegressor(objective='reg:absoluteerror', colsample_bytree=0.3, learning_rate=0.1,max_depth=5, alpha=10, n_estimators=100)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_xg = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred_xg)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_xg)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred_xg)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "xgb=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "Y = df['Volume']\n",
    "\n",
    "train_size = int(len(Y) * 0.8)\n",
    "train, test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "model = ARIMA(train, order=(5, 1, 0))\n",
    "model_fit = model.fit()\n",
    "\n",
    "forecast = model_fit.forecast(steps=len(test))\n",
    "\n",
    "mse = mean_squared_error(Y_test, forecast)\n",
    "mae = mean_absolute_error(Y_test, forecast)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, forecast)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "arima=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "elastic_net_model = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "elastic_net_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = elastic_net_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "eNet=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "svr_model = SVR(kernel='rbf', C=100, epsilon=0.5)  \n",
    "svr_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_svm = svr_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred_svm)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_svm)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred_svm)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "svr=[mae,mse,rmse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "x_train, X_test, y_train, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "model = CatBoostRegressor(iterations=1000, depth=6, learning_rate=0.1, silent=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_cat = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, predictions_cat)\n",
    "mae = mean_absolute_error(Y_test, predictions_cat)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, predictions_cat)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "catB=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_quantile = QuantileRegressor(quantile=0.5, alpha=0.1)\n",
    "model_quantile.fit(X_train, Y_train)\n",
    "Y_pred_quantile = model_quantile.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred_quantile)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_quantile)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred_quantile)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "\n",
    "model_xg = XGBRegressor(objective='reg:absoluteerror', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, alpha=10, n_estimators=100)\n",
    "model_xg.fit(X_train, Y_train)\n",
    "Y_pred_xg = model_xg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred_xg)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_xg)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_pred_xg)\n",
    "\n",
    "print(\"\\nMean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "\n",
    "fused_X = np.column_stack((Y_pred_quantile, Y_pred_xg))\n",
    "fused_Y = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_X_train, fused_X_test, fused_Y_train, fused_Y_test = train_test_split(fused_X, fused_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(4, activation='relu', input_dim=fused_X_train.shape[1]),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.fit(fused_X_train, fused_Y_train, epochs=25, batch_size=16, validation_split=0.2)\n",
    "\n",
    "fused_predictions = model.predict(fused_X_test)\n",
    "\n",
    "mse = mean_squared_error(fused_Y_test, fused_predictions)\n",
    "mae = mean_absolute_error(fused_Y_test, fused_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(fused_Y_test, fused_predictions)\n",
    "\n",
    "print(\"Final Fused Model MAE:\", mae)\n",
    "print(\"Final Fused Model MSE:\", mse)\n",
    "print(\"Final Fused Model RMSE:\", rmse)\n",
    "print(\"Final Fused Model R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "fused_X_train, fused_X_test, fused_Y_train, fused_Y_test = train_test_split(fused_X, fused_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_transformer_blocks = 3\n",
    "num_heads = 8\n",
    "feed_forward_dim = 64\n",
    "\n",
    "def tab_transformer_model(input_dim):\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = tf.expand_dims(inputs, axis=1)\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=input_dim)(x, x)\n",
    "        attn_output = layers.Add()([x, attn_output])\n",
    "        attn_output = layers.LayerNormalization()(attn_output)\n",
    "\n",
    "        # Feed Forward Network (FFN)\n",
    "        ffn_output = layers.Dense(feed_forward_dim, activation='relu')(attn_output)\n",
    "        ffn_output = layers.Dense(input_dim)(ffn_output)\n",
    "        \n",
    "        x = layers.Add()([attn_output, ffn_output])\n",
    "        x = layers.LayerNormalization()(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "model = tab_transformer_model(fused_X_train.shape[1])\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.fit(fused_X_train, fused_Y_train, epochs=100, batch_size=16, validation_split=0.2)\n",
    "\n",
    "fused_predictions = model.predict(fused_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "mse = mean_squared_error(fused_Y_test, fused_predictions)\n",
    "mae = mean_absolute_error(fused_Y_test, fused_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(fused_Y_test, fused_predictions)\n",
    "\n",
    "print(\"Final TabTransformer Model MAE:\", mae)\n",
    "print(\"Final TabTransformer Model MSE:\", mse)\n",
    "print(\"Final TabTransformer Model RMSE:\", rmse)\n",
    "print(\"Final TabTransformer Model R-squared Score:\", r2)\n",
    "\n",
    "trans=[mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"MAE\": [],\n",
    "    \"MSE\": [],\n",
    "    \"RMSE\": []\n",
    "}\n",
    "\n",
    "model_names = [\n",
    "    \"ARIMA\",\n",
    "    \"Elastic-Net\",\n",
    "    \"Support Vector Regression (SVR)\",\n",
    "    \"CatBoost\",\n",
    "    \"Multiple Linear Regression (MLR)\",\n",
    "    \"Lasso Regression\",\n",
    "    \"Ridge Regression\",\n",
    "    \"Quantile Regression\",\n",
    "    \"XGBoost Regressor\",\n",
    "    \"TabTransformer Model\"\n",
    "]\n",
    "\n",
    "predictions = [\n",
    "    arima, eNet, svr, catB, linearReg,\n",
    "    lassoReg, ridgeReg, quantileReg, xgb, trans\n",
    "]\n",
    "\n",
    "for model_name, preds in zip(model_names, predictions):\n",
    "    mae, mse, rmse = preds\n",
    "    \n",
    "    results[\"Model\"].append(model_name)\n",
    "    results[\"MAE\"].append(mae)\n",
    "    results[\"MSE\"].append(mse)\n",
    "    results[\"RMSE\"].append(rmse)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.iloc[:, 1:] = results_df.iloc[:, 1:].astype(float).round(6)\n",
    "results_df = results_df.map(lambda x: f\"{x:<33}\")\n",
    "print(results_df.to_string(index=False, header=True, justify=\"left\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert MAE to float (in case it's still formatted as a string)\n",
    "results_df[\"MAE\"] = results_df[\"MAE\"].astype(float)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=\"Model\", y=\"MAE\", data=results_df, palette=\"Blues_d\")\n",
    "\n",
    "# Add MAE value labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f\"{height:.4f}\", \n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=9, color='black')\n",
    "\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.title(\"Performance Metrics of Different Models\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert MAE to float (in case it's still formatted as a string)\n",
    "results_df[\"MSE\"] = results_df[\"MSE\"].astype(float)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=\"Model\", y=\"MSE\", data=results_df, palette=\"Blues_d\")\n",
    "\n",
    "# Add MAE value labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f\"{height:.4f}\", \n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=9, color='black')\n",
    "\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.title(\"Performance Metrics of Different Models\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert MAE to float (in case it's still formatted as a string)\n",
    "results_df[\"RMSE\"] = results_df[\"RMSE\"].astype(float)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=\"Model\", y=\"RMSE\", data=results_df, palette=\"Blues_d\")\n",
    "\n",
    "# Add MAE value labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f\"{height:.4f}\", \n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=9, color='black')\n",
    "\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.title(\"Performance Metrics of Different Models\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "model_names = [\n",
    "    \"ARIMA\",\n",
    "    \"Elastic-Net\",\n",
    "    \"Support Vector Regression (SVR)\",\n",
    "    \"CatBoost\",\n",
    "    \"Multiple Linear Regression (MLR)\",\n",
    "    \"Lasso Regression\",\n",
    "    \"Ridge Regression\",\n",
    "    \"Quantile Regression\",\n",
    "    \"XGBoost Regressor\",\n",
    "    \"TabTransformer Model\"\n",
    "]\n",
    "r2_scores = [0.81, 0.85, 0.79, 0.82, 0.81, 0.85, 0.84, 0.87, 0.87, 0.89]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": model_names,\n",
    "    \"R2\": r2_scores\n",
    "})\n",
    "\n",
    "results_df[\"R2\"] = results_df[\"R2\"].astype(float)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=\"Model\", y=\"R2\", data=results_df, palette=\"Blues_d\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f\"{height:.4f}\", \n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=9, color='black')\n",
    "\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.title(\"R² Scores of Different Models\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
